{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Palaeoprot/Bear/blob/main/Compile_FASTAs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This uses the EMBL-EBI Job Dispatcher sequence analysis tools framework in 2024.\n",
        "\n",
        "Madeira F et al\n",
        "Nucleic Acids Research, 01 Jul 2024, 52(W1):W521-W525\n",
        "https://doi.org/10.1093/nar/gkae241\n",
        "\n",
        "\n",
        "The **EMBL-EBI Job Dispatcher** sequence analysis tools framework (https://www.ebi.ac.uk/jdispatcher) enables the scientific community to perform a diverse range of sequence analyses using popular bioinformatics applications. Free access to the tools and required sequence datasets is provided through user-friendly web applications, as well as via RESTful and SOAP-based APIs. These are integrated into popular EMBL-EBI resources such as UniProt, InterPro, ENA and Ensembl Genomes. This paper overviews recent improvements to Job Dispatcher, including its brand new website and documentation, enhanced visualisations, improved job management, and a rising trend of user reliance on the service from low- and middle-income regions.\n",
        "\n",
        "Documentation: https://www.uniprot.org/help/api\n",
        "WEBSITE_API = \"https://rest.uniprot.org/\"\n",
        "\n",
        "Documentation: https://www.ebi.ac.uk/proteins/api/doc/\n",
        "PROTEINS_API = \"https://www.ebi.ac.uk/proteins/api\""
      ],
      "metadata": {
        "id": "_7mFMFfefSGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install biopython  # Install the Biopython library"
      ],
      "metadata": {
        "id": "sGKg-qhr4Icx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import requests, sys, json, os, time\n",
        "import pandas as pd\n",
        "from IPython.display import display, HTML, clear_output\n",
        "import ipywidgets as widgets\n",
        "\n",
        "# Documentation: https://www.uniprot.org/help/api\n",
        "WEBSITE_API = \"https://rest.uniprot.org/\""
      ],
      "metadata": {
        "id": "4Sep2zrE0-WW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Collect sequences\n",
        " fetch data, isolate chains, remove duplicates, submit alignment jobs, check if aligned files already exist, and handle cases with a single sequence.\n",
        "\n",
        " [NCBI Taxonomy Browser](https://www.ncbi.nlm.nih.gov/guide/taxonomy/)\n",
        "\n"
      ],
      "metadata": {
        "id": "nb3_j9fH1Zwi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##Select taxonomy and genes\n",
        "import os\n",
        "import requests\n",
        "import pandas as pd\n",
        "from Bio import SeqIO\n",
        "from Bio.Seq import Seq\n",
        "from Bio.SeqRecord import SeqRecord\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output, HTML\n",
        "\n",
        "# Define the taxonomy IDs and their names\n",
        "taxonomy_dict = {\n",
        "    33554: \"Carnivora\",\n",
        "    379584: \"Caniformia\",\n",
        "    379583: \"Feliformia\",\n",
        "    9632: \"Ursidae\",\n",
        "    9615 : \"Canis lupus familiaris\"\n",
        "}\n",
        "\n",
        "# Global variable to store selected taxonomy ID\n",
        "selected_taxonomy_id = None\n",
        "\n",
        "# List of gene names\n",
        "gene_names = [\n",
        "    \"ALB\", \"AEBP1\", \"AHSG\", \"ALPL\", \"APOA1\", \"APOA4\", \"APOE\", \"APOC1\", \"APP\", \"ASPN\",\n",
        "    \"BGLAP\", \"BGN\", \"C3\", \"C8B\", \"C9\", \"CFH\", \"CHAD\", \"CHGA\", \"CLEC11A\", \"CLEC3B\",\n",
        "    \"CLU\", \"COL10A1\", \"COL11A1\", \"COL11A2\", \"COL12A1\", \"COL16A1\", \"COL1A1\", \"COL1A2\",\n",
        "    \"COL21A1\", \"COL22A1\", \"COL24A1\", \"COL2A1\", \"COL3A1\", \"COL4A3\", \"COL4A4\", \"COL4A5\",\n",
        "    \"COL5A1\", \"COL5A2\", \"COL5A3\", \"COL6A1\", \"COL6A3\", \"COL8A1\", \"CRP\", \"DCN\", \"DPT\",\n",
        "    \"EEF1A1\", \"EMILIN1\", \"EZR\", \"F10\", \"F2\", \"F7\", \"F9\", \"FGL2\", \"FMOD\", \"FN1\",\n",
        "    \"GAPDH\", \"GAS6\", \"GC\", \"HAPLN3\", \"HSP90B1\", \"HSPA5\", \"HTRA1\", \"IBSP\", \"IGF1\",\n",
        "    \"IGF2\", \"IGFALS\", \"IGFBP1\", \"KNG1\", \"KRT2\", \"LOX\", \"LRRC15\", \"LUM\", \"MGP\",\n",
        "    \"MMP2\", \"MSN\", \"MYO1B\", \"NUCB1\", \"NUCB2\", \"OGN\", \"OLFML1\", \"OLFML3\", \"OMD\",\n",
        "    \"P4HB\", \"PAM\", \"PCOLCE\", \"PHOSPHO1\", \"POSTN\", \"PROC\", \"PROS1\", \"PRSS2\",\n",
        "    \"SERPINC1\", \"SERPIND1\", \"SERPINF1\", \"SLC8A3\", \"SPARC\", \"SPARCL1\", \"SPP1\",\n",
        "    \"SPP2\", \"TGFB1\", \"THBS1\", \"TNC\", \"TPP1\", \"TUBA1B\", \"VCAN\", \"VIT\", \"VTN\"\n",
        "]\n",
        "\n",
        "# Function to create the output directory based on taxonomy name\n",
        "def create_output_directory(taxonomy_dict, taxonomy_id):\n",
        "    name = taxonomy_dict.get(taxonomy_id, \"Unknown_Taxonomy\")\n",
        "    output_dir = f\"/content/drive/MyDrive/7Papers/26_Ursus_abstrusus/Ancient_Bear/Ancient_Bear_Analysis/FASTAs/Computational_FASTAs/Fasta_{name}/\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    return output_dir\n",
        "\n",
        "# Function to create checkboxes for gene names\n",
        "def create_gene_checkboxes(gene_names):\n",
        "    checkboxes = [widgets.Checkbox(value=True, description=gene) for gene in gene_names]\n",
        "    checkbox_dict = {gene: checkbox for gene, checkbox in zip(gene_names, checkboxes)}\n",
        "    return checkbox_dict\n",
        "\n",
        "# Function to select or deselect all checkboxes\n",
        "def select_all(checkbox_dict, value):\n",
        "    for checkbox in checkbox_dict.values():\n",
        "        checkbox.value = value\n",
        "\n",
        "# Create a function to generate a button for each taxonomy ID\n",
        "def create_buttons(taxonomy_dict):\n",
        "    buttons = []\n",
        "    for tax_id, name in taxonomy_dict.items():\n",
        "        button = widgets.Button(\n",
        "            description=name,\n",
        "            button_style='',  # Initially no style\n",
        "            tooltip=f\"Open {name}\",\n",
        "            style={'description_width': 'initial'}\n",
        "        )\n",
        "\n",
        "        def on_button_click(b, tax_id=tax_id, name=name, button=button):\n",
        "            global selected_taxonomy_id\n",
        "            selected_taxonomy_id = tax_id  # Update the global variable\n",
        "            output_dir = create_output_directory(taxonomy_dict, tax_id)\n",
        "            url = f\"https://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id={tax_id}\"\n",
        "            with open(f\"{output_dir}/taxonomy_id.txt\", \"w\") as f:\n",
        "                f.write(f\"Taxonomy ID: {tax_id}\\nName: {name}\\nURL: {url}\")\n",
        "            clear_output()\n",
        "            display(HTML(f\"<a href='{url}' target='_blank'>Open NCBI Taxonomy Browser to check {name} ({tax_id})</a>\"))\n",
        "            # Reset button styles\n",
        "            for btn in buttons:\n",
        "                btn.button_style = ''  # Reset to no style\n",
        "            # Highlight the selected button\n",
        "            button.button_style = 'success'  # Change color to indicate selection\n",
        "            display(hbox)  # Redisplay the HBox containing buttons\n",
        "            display(HTML(\"<br><h3>Gene Selection</h3>\"))  # Add a break and heading\n",
        "            display(select_all_button, deselect_all_button)  # Redisplay the Select All and Deselect All buttons\n",
        "            display(gene_grid)  # Redisplay the GridBox containing checkboxes\n",
        "            print(f\"Output directory: {output_dir}\")\n",
        "\n",
        "        button.on_click(on_button_click)\n",
        "        buttons.append(button)\n",
        "    return buttons\n",
        "\n",
        "# Create and display buttons in a row\n",
        "buttons = create_buttons(taxonomy_dict)\n",
        "hbox = widgets.HBox(buttons)\n",
        "display(hbox)\n",
        "\n",
        "# Add a break and heading\n",
        "display(HTML(\"<br><h3>Gene Selection</h3>\"))\n",
        "\n",
        "# Create and display checkboxes for gene names\n",
        "gene_checkboxes = create_gene_checkboxes(gene_names)\n",
        "checkbox_widgets = list(gene_checkboxes.values())\n",
        "\n",
        "# Arrange checkboxes in a grid\n",
        "n_cols = 5  # Number of columns in the grid\n",
        "n_rows = (len(checkbox_widgets) + n_cols - 1) // n_cols\n",
        "grid_layout = widgets.Layout(grid_template_columns=f'repeat({n_cols}, 1fr)')\n",
        "gene_grid = widgets.GridBox(checkbox_widgets, layout=grid_layout)\n",
        "\n",
        "# Create a Select All button\n",
        "select_all_button = widgets.Button(description=\"Select All\", button_style='success')\n",
        "select_all_button.on_click(lambda b: select_all(gene_checkboxes, True))\n",
        "\n",
        "# Create a Deselect All button\n",
        "deselect_all_button = widgets.Button(description=\"Deselect All\", button_style='warning')\n",
        "deselect_all_button.on_click(lambda b: select_all(gene_checkboxes, False))\n",
        "\n",
        "# Display the Select All and Deselect All buttons\n",
        "display(select_all_button, deselect_all_button)\n",
        "display(gene_grid)\n"
      ],
      "metadata": {
        "id": "wkxteKWPBsmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure the selected_taxonomy_id is defined before running this cell\n",
        "if selected_taxonomy_id is None:\n",
        "    raise ValueError(\"Please select a taxonomy ID before running this cell.\")\n",
        "\n",
        "# Helper function to download data\n",
        "def get_url(url, **kwargs):\n",
        "    response = requests.get(url, **kwargs)\n",
        "    if not response.ok:\n",
        "        print(response.text)\n",
        "        response.raise_for_status()\n",
        "        sys.exit()\n",
        "    return response\n",
        "\n",
        "# Output directory\n",
        "output_dir = create_output_directory(taxonomy_dict, selected_taxonomy_id)\n",
        "print(f\"Output directory: {output_dir}\")\n",
        "\n",
        "# DataFrame to store the results\n",
        "df = pd.DataFrame(columns=[\"Gene Names\", \"Organism\", \"Organism (ID)\", \"Taxonomic lineage\", \"Length\", \"Sequence\", \"Chain\", \"Aligned Sequence\"])\n",
        "\n",
        "# Check existing files in the output directory\n",
        "existing_files = set(os.listdir(output_dir))\n",
        "\n",
        "# Error log file\n",
        "error_log_file = os.path.join(output_dir, \"error_log.txt\")\n",
        "\n",
        "# Get selected gene names from checkboxes\n",
        "selected_gene_names = [gene for gene, checkbox in gene_checkboxes.items() if checkbox.value]\n",
        "\n",
        "# Iterate over each gene name and fetch the data\n",
        "for gene_name in selected_gene_names:\n",
        "    aligned_file = f\"{gene_name}_aligned.fasta\"\n",
        "    if aligned_file in existing_files:\n",
        "        print(f\"Skipping {gene_name} as it is already aligned.\")\n",
        "        continue\n",
        "\n",
        "    print(f\"Fetching data for gene: {gene_name}\")\n",
        "    url = f\"{WEBSITE_API}/uniprotkb/search?query={gene_name} AND (taxonomy_id:{selected_taxonomy_id})&fields=gene_names,organism_name,organism_id,lineage,length,sequence,ft_chain&format=tsv\"\n",
        "    response = get_url(url)\n",
        "\n",
        "    # Parse the response and add to the DataFrame\n",
        "    lines = response.text.strip().split('\\n')[1:]  # Skip the header\n",
        "    for line in lines:\n",
        "        parts = line.split('\\t')\n",
        "        if len(parts) == 7:\n",
        "            gene, organism, organism_id, lineage, length, sequence, chain_info = parts\n",
        "            # Check if chain_info contains the expected \"CHAIN\" substring\n",
        "            if \"CHAIN\" in chain_info:\n",
        "                try:\n",
        "                    # Handle multiple chains if they exist\n",
        "                    chains = chain_info.split('CHAIN ')\n",
        "                    for chain in chains[1:]:\n",
        "                        chain_start, chain_end = chain.split(';')[0].split('..')\n",
        "                        truncated_sequence = sequence[int(chain_start)-1:int(chain_end)]\n",
        "                        new_row = {\n",
        "                            \"Gene Names\": gene,\n",
        "                            \"Organism\": organism,\n",
        "                            \"Organism (ID)\": organism_id,\n",
        "                            \"Taxonomic lineage\": lineage,\n",
        "                            \"Length\": length,\n",
        "                            \"Sequence\": truncated_sequence,\n",
        "                            \"Chain\": f\"{chain_start}..{chain_end}\",\n",
        "                            \"Aligned Sequence\": \"\"\n",
        "                        }\n",
        "                        df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
        "                except ValueError:\n",
        "                    with open(error_log_file, 'a') as log:\n",
        "                        log.write(f\"Error parsing chain_info for {gene_name}: {chain_info}\\n\")\n",
        "                    print(f\"Error parsing chain_info for {gene_name}: {chain_info}\")\n",
        "            else:\n",
        "                # Use the whole sequence if no valid chain is found\n",
        "                new_row = {\n",
        "                    \"Gene Names\": gene,\n",
        "                    \"Organism\": organism,\n",
        "                    \"Organism (ID)\": organism_id,\n",
        "                    \"Taxonomic lineage\": lineage,\n",
        "                    \"Length\": length,\n",
        "                    \"Sequence\": sequence,\n",
        "                    \"Chain\": \"full_sequence\",\n",
        "                    \"Aligned Sequence\": \"\"\n",
        "                }\n",
        "                df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
        "                print(f\"Using full sequence for {gene_name}: {sequence}\")\n",
        "\n",
        "# Remove duplicate sequences\n",
        "df = df.drop_duplicates(subset=[\"Sequence\"])\n",
        "\n",
        "# Filter out genes with fewer than two sequences\n",
        "df = df.groupby('Gene Names').filter(lambda x: len(x) > 1)\n",
        "\n",
        "# Remove sequences shorter than 100 unless it's the full length of the chain\n",
        "df = df[(df[\"Sequence\"].str.len() >= 100) | (df[\"Chain\"] == \"full_sequence\")]\n",
        "\n",
        "# Save DataFrame to a CSV file\n",
        "df.to_csv(os.path.join(output_dir, f\"uniprot_{selected_taxonomy_id}_proteins_truncated.csv\"), index=False)\n",
        "\n",
        "# Display the DataFrame to see the data\n",
        "display(df)\n",
        "\n",
        "# Function to create a unique identifier with underscores replacing spaces\n",
        "def create_unique_id(row):\n",
        "    return f\"{row['Gene Names']}_{row['Organism']}_{row['Organism (ID)']}_{row.name}\".replace(\" \", \"_\")\n",
        "\n",
        "# Create FASTA files for each gene, ensuring unique identifiers\n",
        "job_ids = []\n",
        "for gene_name in df[\"Gene Names\"].unique():\n",
        "    gene_df = df[df[\"Gene Names\"] == gene_name].copy()\n",
        "    gene_df['Unique_ID'] = gene_df.apply(create_unique_id, axis=1)\n",
        "\n",
        "    fasta_content = \"\"\n",
        "    for _, row in gene_df.iterrows():\n",
        "        fasta_content += f\">{row['Unique_ID']}|{row['Organism'].replace(' ', '_')}|{row['Organism (ID)']}|{row['Chain']}\\n{row['Sequence']}\\n\"\n",
        "\n",
        "    fasta_file = os.path.join(output_dir, f\"{gene_name}.fasta\")\n",
        "    with open(fasta_file, 'w') as file:\n",
        "        file.write(fasta_content)\n",
        "\n",
        "    # Print the FASTA content for debugging\n",
        "    print(f\"FASTA content for {gene_name}:\\n{fasta_content}\")\n",
        "\n",
        "    if len(gene_df) == 1:\n",
        "        # If there is only one sequence, rename the file to indicate it is aligned\n",
        "        os.rename(fasta_file, os.path.join(output_dir, f\"{gene_name}_aligned.fasta\"))\n",
        "        print(f\"Only one sequence for {gene_name}, marked as aligned.\")\n",
        "        continue\n",
        "\n",
        "    # Submit alignment job using Clustal Omega\n",
        "    r = requests.post(\"https://www.ebi.ac.uk/Tools/services/rest/clustalo/run\", data={\n",
        "        \"email\": \"example@example.com\",\n",
        "        \"iterations\": 0,\n",
        "        \"outfmt\": \"fa\",  # Using FASTA format\n",
        "        \"order\": \"aligned\",\n",
        "        \"title\": gene_name,  # Naming the job with the gene name\n",
        "        \"sequence\": fasta_content\n",
        "    })\n",
        "\n",
        "    if r.status_code != 200:\n",
        "        # Log errors during job submission\n",
        "        with open(error_log_file, 'a') as log:\n",
        "            log.write(f\"Error submitting job for {gene_name}: {r.text}\\n\")\n",
        "        print(f\"Error submitting job for {gene_name}: {r.text}\")\n",
        "        continue\n",
        "\n",
        "    job_id = r.text\n",
        "    print(f\"Job ID for {gene_name}: {job_id}\")\n",
        "    job_ids.append((gene_name, job_id))\n",
        "\n",
        "# Save job IDs to a file\n",
        "job_ids_file = os.path.join(output_dir, \"job_ids.txt\")\n",
        "with open(job_ids_file, 'w') as f:\n",
        "    for gene_name, job_id in job_ids:\n",
        "        f.write(f\"{gene_name}\\t{job_id}\\n\")\n",
        "\n",
        "print(f\"Job IDs saved to {job_ids_file}\")\n"
      ],
      "metadata": {
        "id": "VNZTjE8yQiQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assembling Results into a DataFrame and Saving to a TSV File\n",
        "This script will check the status of the alignment jobs, retrieve the results, update the DataFrame, and save the results to a TSV file."
      ],
      "metadata": {
        "id": "l_5PGE2y1L7e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import requests\n",
        "import pandas as pd\n",
        "from Bio import SeqIO\n",
        "from Bio.Seq import Seq\n",
        "from Bio.SeqRecord import SeqRecord\n",
        "\n",
        "# Ensure the selected_taxonomy_id is defined and not an empty string before running this cell\n",
        "if selected_taxonomy_id is None or selected_taxonomy_id == \"\":\n",
        "    raise ValueError(\"Please select a valid taxonomy ID before running this cell.\")\n",
        "\n",
        "# Helper function to download data\n",
        "def get_url(url, **kwargs):\n",
        "    response = requests.get(url, **kwargs)\n",
        "    if not response.ok:\n",
        "        print(response.text)\n",
        "        response.raise_for_status()\n",
        "    return response\n",
        "\n",
        "# Output directory\n",
        "output_dir = create_output_directory(taxonomy_dict, selected_taxonomy_id)\n",
        "print(f\"Output directory: {output_dir}\")\n",
        "\n",
        "# DataFrame to store the results\n",
        "df = pd.DataFrame(columns=[\"Gene Names\", \"Organism\", \"Organism (ID)\", \"Taxonomic lineage\", \"Length\", \"Sequence\", \"Chain\", \"Aligned Sequence\"])\n",
        "\n",
        "# Check existing files in the output directory\n",
        "existing_files = set(os.listdir(output_dir))\n",
        "\n",
        "# Error log file\n",
        "error_log_file = os.path.join(output_dir, \"error_log.txt\")\n",
        "\n",
        "# Get selected gene names from checkboxes\n",
        "selected_gene_names = [gene for gene, checkbox in gene_checkboxes.items() if checkbox.value]\n",
        "\n",
        "# Iterate over each gene name and fetch the data\n",
        "for gene_name in selected_gene_names:\n",
        "    aligned_file = f\"{gene_name}_aligned.fasta\"\n",
        "    if aligned_file in existing_files:\n",
        "        print(f\"Skipping {gene_name} as it is already aligned.\")\n",
        "        continue\n",
        "\n",
        "    print(f\"Fetching data for gene: {gene_name}\")\n",
        "    url = f\"https://www.ebi.ac.uk/proteins/api/proteins?gene={gene_name}&taxid={selected_taxonomy_id}&format=tsv\"\n",
        "    response = get_url(url)\n",
        "\n",
        "    # Parse the response and add to the DataFrame\n",
        "    lines = response.text.strip().split('\\n')[1:]  # Skip the header\n",
        "    for line in lines:\n",
        "        parts = line.split('\\t')\n",
        "        if len(parts) == 7:\n",
        "            gene, organism, organism_id, lineage, length, sequence, chain_info = parts\n",
        "            # Check if chain_info contains the expected \"CHAIN\" substring\n",
        "            if \"CHAIN\" in chain_info:\n",
        "                try:\n",
        "                    # Handle multiple chains if they exist\n",
        "                    chains = chain_info.split('CHAIN ')\n",
        "                    for chain in chains[1:]:\n",
        "                        chain_start, chain_end = chain.split(';')[0].split('..')\n",
        "                        truncated_sequence = sequence[int(chain_start)-1:int(chain_end)]\n",
        "                        new_row = {\n",
        "                            \"Gene Names\": gene,\n",
        "                            \"Organism\": organism,\n",
        "                            \"Organism (ID)\": organism_id,\n",
        "                            \"Taxonomic lineage\": lineage,\n",
        "                            \"Length\": length,\n",
        "                            \"Sequence\": truncated_sequence,\n",
        "                            \"Chain\": f\"{chain_start}..{chain_end}\",\n",
        "                            \"Aligned Sequence\": \"\"\n",
        "                        }\n",
        "                        df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
        "                except ValueError:\n",
        "                    with open(error_log_file, 'a') as log:\n",
        "                        log.write(f\"Error parsing chain_info for {gene_name}: {chain_info}\\n\")\n",
        "                    print(f\"Error parsing chain_info for {gene_name}: {chain_info}\")\n",
        "            else:\n",
        "                # Use the whole sequence if no valid chain is found\n",
        "                new_row = {\n",
        "                    \"Gene Names\": gene,\n",
        "                    \"Organism\": organism,\n",
        "                    \"Organism (ID)\": organism_id,\n",
        "                    \"Taxonomic lineage\": lineage,\n",
        "                    \"Length\": length,\n",
        "                    \"Sequence\": sequence,\n",
        "                    \"Chain\": \"full_sequence\",\n",
        "                    \"Aligned Sequence\": \"\"\n",
        "                }\n",
        "                df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
        "                print(f\"Using full sequence for {gene_name}: {sequence}\")\n",
        "\n",
        "# Remove duplicate sequences\n",
        "df = df.drop_duplicates(subset=[\"Sequence\"])\n",
        "\n",
        "# Filter out genes with fewer than two sequences\n",
        "df = df.groupby('Gene Names').filter(lambda x: len(x) > 1)\n",
        "\n",
        "# Remove sequences shorter than 100 unless it's the full length of the chain\n",
        "df = df[(df[\"Sequence\"].str.len() >= 100) | (df[\"Chain\"] == \"full_sequence\")]\n",
        "\n",
        "# Save DataFrame to a CSV file\n",
        "df.to_csv(os.path.join(output_dir, f\"uniprot_{selected_taxonomy_id}_proteins_truncated.csv\"), index=False)\n",
        "\n",
        "# Display the DataFrame to see the data\n",
        "display(df)\n",
        "\n",
        "# Function to create a unique identifier with underscores replacing spaces\n",
        "def create_unique_id(row):\n",
        "    return f\"{row['Gene Names']}_{row['Organism']}_{row['Organism (ID)']}_{row.name}\".replace(\" \", \"_\")\n",
        "\n",
        "# Create FASTA files for each gene, ensuring unique identifiers\n",
        "job_ids = []\n",
        "for gene_name in df[\"Gene Names\"].unique():\n",
        "    gene_df = df[df[\"Gene Names\"] == gene_name].copy()\n",
        "    gene_df['Unique_ID'] = gene_df.apply(create_unique_id, axis=1)\n",
        "\n",
        "    fasta_content = \"\"\n",
        "    for _, row in gene_df.iterrows():\n",
        "        fasta_content += f\">{row['Unique_ID']}|{row['Organism'].replace(' ', '_')}|{row['Organism (ID)']}|{row['Chain']}\\n{row['Sequence']}\\n\"\n",
        "\n",
        "    fasta_file = os.path.join(output_dir, f\"{gene_name}.fasta\")\n",
        "    with open(fasta_file, 'w') as file:\n",
        "        file.write(fasta_content)\n",
        "\n",
        "    # Print the FASTA content for debugging\n",
        "    print(f\"FASTA content for {gene_name}:\\n{fasta_content}\")\n",
        "\n",
        "    if len(gene_df) == 1:\n",
        "        # If there is only one sequence, rename the file to indicate it is aligned\n",
        "        os.rename(fasta_file, os.path.join(output_dir, f\"{gene_name}_aligned.fasta\"))\n",
        "        print(f\"Only one sequence for {gene_name}, marked as aligned.\")\n",
        "        continue\n",
        "\n",
        "    # Submit alignment job using Clustal Omega\n",
        "    r = requests.post(\"https://www.ebi.ac.uk/Tools/services/rest/clustalo/run\", data={\n",
        "        \"email\": \"example@example.com\",\n",
        "        \"iterations\": 0,\n",
        "        \"outfmt\": \"fa\",  # Using FASTA format\n",
        "        \"order\": \"aligned\",\n",
        "        \"title\": gene_name,  # Naming the job with the gene name\n",
        "        \"sequence\": fasta_content\n",
        "    })\n",
        "\n",
        "    if r.status_code != 200:\n",
        "        # Log errors during job submission\n",
        "        with open(error_log_file, 'a') as log:\n",
        "            log.write(f\"Error submitting job for {gene_name}: {r.text}\\n\")\n",
        "        print(f\"Error submitting job for {gene_name}: {r.text}\")\n",
        "        continue\n",
        "\n",
        "    job_id = r.text\n",
        "    print(f\"Job ID for {gene_name}: {job_id}\")\n",
        "    job_ids.append((gene_name, job_id))\n",
        "\n",
        "# Save job IDs to a file\n",
        "job_ids_file = os.path.join(output_dir, \"job_ids.txt\")\n",
        "with open(job_ids_file, 'w') as f:\n",
        "    for gene_name, job_id in job_ids:\n",
        "        f.write(f\"{gene_name}\\t{job_id}\\n\")\n",
        "\n",
        "print(f\"Job IDs saved to {job_ids_file}\")\n"
      ],
      "metadata": {
        "id": "KXgukawZdBPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import time  # Import the time module# Set directories\n",
        "# selected_taxonomy_name = taxonomy_dict.get(selected_taxonomy_id, \"Unknown_Taxonomy\") # Get name from taxonomy ID\n",
        "# input_directory = f\"/content/drive/MyDrive/7Papers/26_Ursus_abstrusus/Ancient_Bear/Ancient_Bear_Analysis/FASTAs/Computational_FASTAs/Fasta_{selected_taxonomy_name}/\"\n",
        "# job_ids_file = os.path.join(input_directory, \"job_ids.txt\")\n",
        "# output_file = os.path.join(input_directory, \"uniprot_bear_proteins_aligned.csv\")\n",
        "# fasta_output_file = os.path.join(input_directory, \"combined_bear_proteins.fasta\")\n",
        "# error_log_file = os.path.join(input_directory, \"error_log.txt\")\n",
        "\n",
        "\n",
        "# # Helper function to download data\n",
        "# def get_url(url, **kwargs):\n",
        "#     response = requests.get(url, **kwargs)\n",
        "#     if not response.ok:\n",
        "#         print(response.text)\n",
        "#         response.raise_for_status()\n",
        "#     return response\n",
        "\n",
        "# # Read job IDs from the file, handling potential formatting issues\n",
        "# job_ids = []\n",
        "# with open(job_ids_file, 'r') as f:\n",
        "#     for line in f:\n",
        "#         parts = line.strip().split('\\t')\n",
        "#         if len(parts) == 2:  # Check if the line has the expected two parts\n",
        "#             gene_name, job_id = parts\n",
        "#             job_ids.append((gene_name, job_id))\n",
        "#         else:\n",
        "#             print(f\"Skipping malformed line: {line.strip()}\")  # Log or handle malformed lines\n",
        "\n",
        "# # Initialize DataFrame to store the results\n",
        "# df = pd.DataFrame(columns=[\"Gene Names\", \"Organism\", \"Organism (ID)\", \"Taxonomic lineage\", \"Length\", \"Sequence\", \"Chain\", \"Aligned Sequence\"])\n",
        "\n",
        "# # Process each job ID\n",
        "# for gene_name, job_id in job_ids:\n",
        "#     status_url = f\"https://www.ebi.ac.uk/Tools/services/rest/clustalo/status/{job_id}\"\n",
        "#     result_url = f\"https://www.ebi.ac.uk/Tools/services/rest/clustalo/result/{job_id}/fa\"\n",
        "\n",
        "#     # Check job status\n",
        "#     status_response = get_url(status_url)\n",
        "#     status = status_response.text.strip()\n",
        "#     print(f\"Status for {gene_name} ({job_id}): {status}\")\n",
        "\n",
        "#     if status == \"FINISHED\":\n",
        "#         # Get the alignment result\n",
        "#         result_response = get_url(result_url)\n",
        "#         aligned_sequences = result_response.text\n",
        "\n",
        "#         # Save the alignment result to a file\n",
        "#         aligned_fasta_file = os.path.join(input_directory, f\"{gene_name}_aligned.fasta\")\n",
        "#         with open(aligned_fasta_file, 'w') as file:\n",
        "#             file.write(aligned_sequences)\n",
        "#         print(f\"Alignment result saved to {aligned_fasta_file}\")\n",
        "\n",
        "#         # Parse the aligned sequences and add to the DataFrame\n",
        "#         for record in SeqIO.parse(aligned_fasta_file, \"fasta\"):\n",
        "#             aligned_sequence = str(record.seq)\n",
        "#             parts = record.description.split('|')\n",
        "#             if len(parts) >= 4:\n",
        "#                 organism = parts[1].strip()\n",
        "#                 organism_id = parts[2].strip()\n",
        "#                 chain = parts[3].strip()\n",
        "#             else:\n",
        "#                 organism = \"Unknown\"\n",
        "#                 organism_id = \"Unknown\"\n",
        "#                 chain = \"Unknown\"\n",
        "#                 with open(error_log_file, 'a') as log:\n",
        "#                     log.write(f\"Incomplete description for {record.id} in gene {gene_name}: {record.description}\\n\")\n",
        "\n",
        "#             df.loc[len(df)] = {\n",
        "#                 \"Gene Names\": gene_name,\n",
        "#                 \"Organism\": organism,\n",
        "#                 \"Organism (ID)\": organism_id,\n",
        "#                 \"Taxonomic lineage\": \"\",  # This can be filled with the correct lineage if available\n",
        "#                 \"Length\": len(aligned_sequence),\n",
        "#                 \"Sequence\": \"\",  # Original sequence is not required here\n",
        "#                 \"Chain\": chain,\n",
        "#                 \"Aligned Sequence\": aligned_sequence\n",
        "#             }\n",
        "\n",
        "#     else:\n",
        "#         # Log any issues\n",
        "#         with open(error_log_file, 'a') as log:\n",
        "#             log.write(f\"Job {job_id} for gene {gene_name} is not finished or has errors: Status {status}\\n\")\n",
        "#         print(f\"Job {job_id} for gene {gene_name} is not finished or has errors: Status {status}\")\n",
        "\n",
        "#     # Avoid hitting the server too hard\n",
        "#     sleep(5)\n",
        "\n",
        "# # Save DataFrame to CSV\n",
        "# df.to_csv(output_file, index=False)\n",
        "# print(f\"Aligned sequences DataFrame saved to {output_file}\")\n",
        "\n",
        "# # Combine all aligned sequences into a single FASTA file\n",
        "# all_sequences = []\n",
        "# for _, row in df.iterrows():\n",
        "#     record = SeqRecord(Seq(row['Aligned Sequence']),\n",
        "#                        id=f\"{row['Gene Names']}_{row.name}\",\n",
        "#                        description=f\"GN={row['Gene Names']} | OS={row['Organism']} | OID={row['Organism (ID)']} | Chain={row['Chain']}\")\n",
        "#     all_sequences.append(record)\n",
        "\n",
        "# SeqIO.write(all_sequences, fasta_output_file, \"fasta\")\n",
        "# print(f\"Combined FASTA file created: {fasta_output_file}\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "7FbyxSXtsgnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XAYhDudoaPcG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}